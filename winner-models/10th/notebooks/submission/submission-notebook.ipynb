{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations, product\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "from IPython.display import display_html\n",
    "from sklearn.utils import shuffle\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "import time\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('max_column', None)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED=42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prices\n",
    "df_train = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\n",
    "df_train[\"Date\"] = pd.to_datetime(df_train[\"Date\"])\n",
    "# Stocks List\n",
    "stock_list = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")\n",
    "stock_list['NewMarketSegment'] = stock_list['NewMarketSegment'].str.replace(\" \\(Foreign Stock\\)\",\"\")\n",
    "# Financials\n",
    "financials = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv\")[['Date', 'SecuritiesCode', 'TypeOfDocument','TypeOfCurrentPeriod']]\n",
    "financials[\"Date\"] = pd.to_datetime(financials[\"Date\"])\n",
    "financials_train = pd.concat([financials['TypeOfDocument'].str.split('_', expand=True), financials], axis = 1)\n",
    "financials_train[0] = financials_train[0].str.replace('1Q','').str.replace('2Q','').str.replace('3Q','').str.replace('FY','')\n",
    "financials_train = pd.get_dummies(financials_train, columns=[0,1,2,'TypeOfCurrentPeriod']).drop(columns=['TypeOfDocument'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_simulations(df_temp_prediction, weights, NUM_SIMULATIONS = 10000):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df_temp_prediction (pd.DataFrame): daily df with Target prediction\n",
    "        weights (list): # weights\n",
    "        NUM_SIMULATIONS (int): Number of iteration to simulate different scenarios\n",
    "    Returns:\n",
    "        (dict): simulation results\n",
    "    \"\"\"\n",
    "    dict_simulations = {}\n",
    "    for i in range(NUM_SIMULATIONS): \n",
    "        df_temp_prediction_sim = shuffle(df_temp_prediction.copy()).reset_index(drop=True)\n",
    "        df_temp_prediction_sim['Rank'] = df_temp_prediction_sim.index.astype(int)\n",
    "\n",
    "        # Day Spread Estimation\n",
    "        w_temp_BUY = (np.array(df_temp_prediction_sim['Target'][:200]) * weights).sum() / weights.mean()\n",
    "        w_temp_SHORT = (np.array(df_temp_prediction_sim['Target'][-200:])[::-1] * weights).sum() / weights.mean()\n",
    "        spread = w_temp_BUY - w_temp_SHORT\n",
    "        \n",
    "        dict_simulations[i] = (\n",
    "            df_temp_prediction_sim, \n",
    "            spread, \n",
    "            None # useless\n",
    "            ) \n",
    "\n",
    "    return dict_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpx_tokyo_market_prediction\n",
    "env = jpx_tokyo_market_prediction.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling = df_train.drop(columns=['Target'], axis = 1).copy()\n",
    "df_rolling = df_rolling[df_rolling['Date'].isin(sorted(df_rolling['Date'].unique(), reverse=True)[:16])]\n",
    "\n",
    "x = [0,1]\n",
    "POLYs = [1] # Degrees of the polynomial to be averaged\n",
    "LAGs = [3,4,5,6,7] # Past intervals to be mediated in the forecast\n",
    "TARGET_SPREAD_VALUE = 0.4 #41853716597983\n",
    "\n",
    "\n",
    "previous_selection_frames = []\n",
    "previous_prices_frames = []\n",
    "real_spread_history = []\n",
    "\n",
    "for (prices, _, financials, _, _, sample_prediction) in iter_test: # Iterate over days\n",
    "    #print(prices.Date.iloc[0])\n",
    "    \n",
    "    df_rolling = pd.concat([df_rolling, prices.copy()]).sort_values([\"SecuritiesCode\", \"Date\"])\n",
    "    df_rolling['is_no_price'] = 0\n",
    "    df_rolling.loc[np.isnan(df_rolling['Close']), 'is_no_price'] = 1\n",
    "    df_rolling = df_rolling.ffill()\n",
    "    df_rolling['Date'] = pd.to_datetime(df_rolling['Date'])\n",
    "    \n",
    "    df_rolling_last = df_rolling.copy()\n",
    "\n",
    "    # Append Closed price shifted to df\n",
    "    for shift_temp in reversed(range(1,8)):\n",
    "        df_rolling_last[f\"shift_{shift_temp}\"] = df_rolling_last.groupby('SecuritiesCode')['Close'].shift(shift_temp)\n",
    "\n",
    "    df_rolling_last_new = df_rolling_last[df_rolling_last['Date'] == prices.Date.iloc[0]]\n",
    "    df_rolling_last_new['shift_0'] = df_rolling_last_new['Close']\n",
    "\n",
    "    target_columns = []\n",
    "    r2_columns = []\n",
    "    for grado_poly in POLYs: # For each polynomial degrees\n",
    "        for lag in LAGs: # For eache LAGs\n",
    "            baseline_array = []\n",
    "            historical_shift_columns = []\n",
    "            for i in range(lag):\n",
    "                baseline_array.append(i)\n",
    "                historical_shift_columns.append(f'shift_{lag-i-1}')\n",
    "\n",
    "            temp_array = np.array(df_rolling_last_new[historical_shift_columns])\n",
    "\n",
    "            df_rolling_last_new[f'closed_poly{grado_poly}_{lag}'] = [np.poly1d(np.polyfit(np.array(baseline_array),arr,grado_poly))(lag) for arr in temp_array] # Poly fit 1d for day + 1 \n",
    "            df_rolling_last_new[f'closed_poly{grado_poly}_{lag}+1'] = [np.poly1d(np.polyfit(np.array(baseline_array),arr,grado_poly))(lag+1) for arr in temp_array] # Poly fit 1d for day + 2\n",
    "            df_rolling_last_new[f'poly{grado_poly}_{lag}_r2'] = [r2_score(arr, np.poly1d(np.polyfit(np.array(baseline_array),arr,grado_poly))(baseline_array)) for arr in temp_array] # R2 Error on past\n",
    "\n",
    "            # Fix no sense drop \n",
    "            df_rolling_last_new.loc[df_rolling_last_new[f'closed_poly{grado_poly}_{lag}'] <= 0, f'closed_poly{grado_poly}_{lag}'] = df_rolling_last_new[df_rolling_last_new[f'closed_poly{grado_poly}_{lag}'] <= 0]['shift_0']\n",
    "            df_rolling_last_new.loc[df_rolling_last_new[f'closed_poly{grado_poly}_{lag}+1'] <= 0, f'closed_poly{grado_poly}_{lag}+1'] = df_rolling_last_new[df_rolling_last_new[f'closed_poly{grado_poly}_{lag}+1'] <= 0][f'closed_poly{grado_poly}_{lag}']\n",
    "            \n",
    "            # Calcolate current estimated Target\n",
    "            df_rolling_last_new[f'target_poly{grado_poly}_lag_{lag}'] = (df_rolling_last_new[f'closed_poly{grado_poly}_{lag}+1'] - df_rolling_last_new[f'closed_poly{grado_poly}_{lag}']) / df_rolling_last_new[f'closed_poly{grado_poly}_{lag}']\n",
    "            \n",
    "            target_columns.append(f'target_poly{grado_poly}_lag_{lag}')\n",
    "            r2_columns.append(f'poly{grado_poly}_{lag}_r2')\n",
    "\n",
    "    # Ensamble of target results by weighted average on R2 error on past data\n",
    "    target_matrix_w_weights = (np.array(df_rolling_last_new[target_columns]) * np.array(df_rolling_last_new[r2_columns])).sum(axis = 1)\n",
    "    sum_weights = np.array(df_rolling_last_new[r2_columns]).sum(axis = 1)\n",
    "    df_rolling_last_new['predicted_target'] = target_matrix_w_weights/sum_weights \n",
    "    \n",
    "    df_rolling_last_new.loc[df_rolling_last_new['is_no_price'] == 1, 'predicted_target'] = 0.0 # Without Close Price set to 0\n",
    "\n",
    "    target_map = df_rolling_last_new.groupby('SecuritiesCode')['predicted_target'].mean() \n",
    "    \n",
    "    ## Apply the estimated targets for each stock\n",
    "    sample_prediction_new = sample_prediction.copy()\n",
    "    sample_prediction_new['Target'] = sample_prediction_new['SecuritiesCode'].map(target_map.to_dict())\n",
    "    sample_prediction_new.fillna(0, inplace = True) # Set to 0 if mapping fails\n",
    "    sample_prediction_new = sample_prediction_new.drop(columns = ['Rank'], axis = 1) # Removal of the Rank dummy\n",
    "    \n",
    "    # Simulation of n scenarios to find the one with the best ranking (with respect to best spread analysis)\n",
    "    dict_simulations = day_simulations(sample_prediction_new, weights = np.linspace(start=2, stop=1, num=200), NUM_SIMULATIONS = 10000) # Increase the number of simulations for a better result (slower execution)\n",
    "    \n",
    "    # Selection of the best simulation based on the distance to the established spread target value\n",
    "    spread_simulations = [abs(v[1] - random.uniform(0.3,0.5)) for v in dict_simulations.values()]\n",
    "    best_idx_list = np.argsort(spread_simulations) \n",
    "    best_combination = dict_simulations[best_idx_list[0]][0] # Pick the best combination of spread \n",
    "    \n",
    "    # Apply Rank\n",
    "    sample_prediction['Rank'] = sample_prediction[\"SecuritiesCode\"].map(pd.Series(best_combination.Rank.values, index=best_combination.SecuritiesCode).to_dict())\n",
    "    \n",
    "    # Update environment with predicted Rank\n",
    "    env.predict(sample_prediction)\n",
    "\n",
    "    previous_prices_frames.append(prices.copy()[['Date', 'SecuritiesCode', 'Close']])\n",
    "    previous_selection_frames.append(sample_prediction.copy())\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}